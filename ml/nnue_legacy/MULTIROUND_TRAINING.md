# å¤šè½® NNUE è®­ç»ƒç³»ç»Ÿ

## æ¦‚è¿°

å¤šè½®è®­ç»ƒç³»ç»Ÿå®ç°äº†æ™ºèƒ½çš„å‚æ•°ç»§æ‰¿å’ŒåŠ¨æ€ä¼˜åŒ–ç­–ç•¥ï¼Œç›¸æ¯”å•è½®å¤§æ•°æ®é›†è®­ç»ƒå…·æœ‰æ›´å¥½çš„æ•ˆæœå’Œç¨³å®šæ€§ã€‚

## æ ¸å¿ƒä¼˜åŠ¿

### ğŸ¯ **è„šæœ¬æ–¹å¼ vs é…ç½®æ–‡ä»¶æ–¹å¼**

| ç‰¹æ€§ | è„šæœ¬æ–¹å¼ âœ… | é…ç½®æ–‡ä»¶æ–¹å¼ |
|------|-------------|--------------|
| **å‚æ•°ç»§æ‰¿** | âœ… å®Œæ•´ç»§æ‰¿å­¦ä¹ ç‡ã€ä¼˜åŒ–å™¨çŠ¶æ€ | âŒ æ¯è½®é‡æ–°å¼€å§‹ |
| **åŠ¨æ€è°ƒæ•´** | âœ… æ ¹æ®è®­ç»ƒæ•ˆæœæ™ºèƒ½è°ƒæ•´ | âŒ é™æ€é…ç½® |
| **çŠ¶æ€ç®¡ç†** | âœ… å®Œæ•´çš„æ£€æŸ¥ç‚¹ç³»ç»Ÿ | âŒ æ— çŠ¶æ€ç®¡ç† |
| **æ¢å¤è®­ç»ƒ** | âœ… æ”¯æŒä¸­æ–­æ¢å¤ | âŒ æ— æ³•æ¢å¤ |
| **å¤æ‚åº¦** | ä¸­ç­‰ | ç®€å• |

**ç»“è®ºï¼šè„šæœ¬æ–¹å¼æ˜¾è‘—ä¼˜äºé…ç½®æ–‡ä»¶æ–¹å¼**

## å‚æ•°ç»§æ‰¿æœºåˆ¶

### ğŸ§  **è‡ªåŠ¨ç»§æ‰¿çš„å‚æ•°**

1. **å­¦ä¹ ç‡ç»§æ‰¿**
   ```python
   # æ ¹æ®å‰ä¸€è½®è®­ç»ƒæ•ˆæœåŠ¨æ€è°ƒæ•´
   if improvement > 5%:
       lr *= 1.05  # è®­ç»ƒæ•ˆæœå¥½ï¼Œç•¥å¾®æå‡å­¦ä¹ ç‡
   elif improvement < 1%:
       lr *= 0.8   # æ”¹å–„ç¼“æ…¢ï¼Œé™ä½å­¦ä¹ ç‡
   ```

2. **ä¼˜åŒ–å™¨çŠ¶æ€ç»§æ‰¿**
   ```python
   checkpoint = {
       'optimizer_state_dict': optimizer.state_dict(),
       'scheduler_state_dict': scheduler.state_dict(),
       'best_val_loss': best_val_loss,
       'learning_rate': current_lr
   }
   ```

3. **ğŸ”¥ æ¨¡å‹æƒé‡ç»§æ‰¿ï¼ˆè¿ç§»å­¦ä¹ ï¼‰**
   ```python
   # æ™ºèƒ½è¿ç§»å­¦ä¹ ç­–ç•¥
   if round_num <= 3:
       strategy = "full"          # å®Œå…¨è¿ç§»
       lr_scale = 0.5
   elif round_num <= 5:
       strategy = "fine-tune"     # å¾®è°ƒ
       lr_scale = 0.3  
   else:
       strategy = "fine-tune"     # ç²¾ç»†å¾®è°ƒ
       lr_scale = 0.1
   ```

4. **è®­ç»ƒå†å²ç»§æ‰¿**
   - éªŒè¯æŸå¤±å†å²
   - æ¢¯åº¦èŒƒæ•°å†å²
   - å­¦ä¹ ç‡è°ƒæ•´å†å²

## è¿ç§»å­¦ä¹ ç­–ç•¥

### ğŸ¯ **å››ç§è¿ç§»å­¦ä¹ ç­–ç•¥**

| ç­–ç•¥ | æè¿° | é€‚ç”¨åœºæ™¯ | å­¦ä¹ ç‡å»ºè®® |
|------|------|----------|------------|
| **full** | å®Œå…¨è¿ç§»æ‰€æœ‰å…¼å®¹æƒé‡ | æ—©æœŸè½®æ¬¡(1-3) | 0.3-0.5x |
| **fine-tune** | åŠ è½½æƒé‡ï¼Œå°å­¦ä¹ ç‡å¾®è°ƒ | ä¸­åæœŸè½®æ¬¡(4+) | 0.1-0.3x |
| **freeze-input** | å†»ç»“è¾“å…¥å±‚ï¼Œè®­ç»ƒå…¶ä»–å±‚ | ç‰¹å¾ç¨³å®šåœºæ™¯ | 0.2-0.4x |
| **freeze-hidden** | å†»ç»“éšè—å±‚ï¼Œè®­ç»ƒè¾“å…¥è¾“å‡º | æ¶æ„è°ƒæ•´åœºæ™¯ | 0.2-0.4x |

### ğŸš€ **è¿ç§»å­¦ä¹ ä¼˜åŠ¿**

1. **æ˜¾è‘—åŠ é€Ÿæ”¶æ•›**ï¼šä»å·²è®­ç»ƒæ¨¡å‹å¼€å§‹ï¼Œè€Œééšæœºåˆå§‹åŒ–
2. **æå‡æœ€ç»ˆæ€§èƒ½**ï¼šåˆ©ç”¨å‰ä¸€è½®å­¦åˆ°çš„ç‰¹å¾è¡¨ç¤º
3. **å‡å°‘è®­ç»ƒæ—¶é—´**ï¼šæ¯è½®è®­ç»ƒæ›´å¿«è¾¾åˆ°æ”¶æ•›
4. **å¢å¼ºç¨³å®šæ€§**ï¼šé¿å…è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¤§å¹…éœ‡è¡

## ä½¿ç”¨æ–¹æ³•

### ğŸš€ **å¿«é€Ÿå¼€å§‹**

```bash
# åŸºæœ¬ç”¨æ³•
python train_multiround.py --config configs/multiround_base.json

# æŒ‡å®šè¾“å‡ºç›®å½•å’Œè½®æ¬¡
python train_multiround.py \
    --config configs/multiround_base.json \
    --output-dir my_training \
    --max-rounds 8

# æ¢å¤ä¸­æ–­çš„è®­ç»ƒ
python train_multiround.py \
    --config configs/multiround_base.json \
    --resume
```

### ğŸ“‹ **è®­ç»ƒç­–ç•¥**

| è½®æ¬¡ | ä½ç½®æ•°é‡ | Epochs | å­¦ä¹ ç‡ | æ‰¹é‡å¤§å° | é˜¶æ®µæè¿° |
|------|----------|--------|--------|----------|----------|
| 1 | 30,000 | 80 | 0.003 | 4,096 | æ¢ç´¢é˜¶æ®µï¼šå¿«é€Ÿæ”¶æ•› |
| 2 | 50,000 | 120 | 0.002 | 6,144 | ç¨³å®šå­¦ä¹ ï¼šå¹³è¡¡ä¼˜åŒ– |
| 3 | 80,000 | 150 | 0.0015 | 8,192 | æ·±åŒ–å­¦ä¹ ï¼šå¢åŠ æ•°æ® |
| 4 | 100,000 | 180 | 0.001 | 8,192 | ç²¾ç»†è°ƒæ•´ï¼šå¤§æ•°æ®é›† |
| 5 | 120,000 | 200 | 0.0008 | 10,240 | ä¼˜åŒ–é˜¶æ®µï¼šé™ä½å­¦ä¹ ç‡ |
| 6 | 150,000 | 250 | 0.0005 | 10,240 | æ”¶æ•›é˜¶æ®µï¼šæœ€ç»ˆä¼˜åŒ– |

### ğŸ”§ **é…ç½®æ–‡ä»¶ç¤ºä¾‹**

```json
{
  "_description": "å¤šè½®è®­ç»ƒåŸºç¡€é…ç½®",
  "pipeline": true,
  "perfect-db": "path/to/perfect/database",
  
  "lr-scheduler": "adaptive",
  "lr-auto-scale": false,
  "feature-size": 115,
  "hidden-size": 256,
  "val-split": 0.1,
  
  "device": "auto",
  "plot": true,
  "save-csv": true
}
```

## æ™ºèƒ½ç‰¹æ€§

### ğŸ§  **åŠ¨æ€å­¦ä¹ ç‡è°ƒæ•´**

```python
def update_inherited_parameters(self, round_results):
    improvement = (prev_loss - current_loss) / prev_loss
    
    if improvement > 0.05:  # æ˜¾è‘—æ”¹å–„
        self.inherited_lr *= 1.05
        logger.info("ğŸ“ˆ è®­ç»ƒæ”¹å–„æ˜¾è‘—ï¼Œå­¦ä¹ ç‡æå‡")
        
    elif improvement < 0.01:  # æ”¹å–„ç¼“æ…¢
        self.inherited_lr *= 0.8
        logger.info("ğŸ“‰ æ”¹å–„ç¼“æ…¢ï¼Œå­¦ä¹ ç‡é™ä½")
```

### ğŸ’¾ **å®Œæ•´çš„æ£€æŸ¥ç‚¹ç³»ç»Ÿ**

```python
checkpoint = {
    'epoch': epoch + 1,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'scheduler_state_dict': scheduler.state_dict(),
    'best_val_loss': best_val_loss,
    'learning_rate': current_lr,
    'args': vars(args)
}
```

### ğŸ”„ **è®­ç»ƒçŠ¶æ€ç®¡ç†**

```python
training_state = {
    "current_round": 3,
    "round_history": [...],
    "best_val_loss": 0.001234,
    "best_round": 2,
    "inherited_lr": 0.0015,
    "last_model_path": "round_02/model.bin"
}
```

## è¾“å‡ºç»“æ„

```
multiround_output/
â”œâ”€â”€ round_01/
â”‚   â”œâ”€â”€ nnue_model_round_01.bin      # æ¨¡å‹æ–‡ä»¶
â”‚   â”œâ”€â”€ nnue_model_round_01.checkpoint # å®Œæ•´æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ training_metrics.csv         # è®­ç»ƒæŒ‡æ ‡
â”‚   â””â”€â”€ plots/                       # å¯è§†åŒ–å›¾è¡¨
â”œâ”€â”€ round_02/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ round_01_config.json             # è½®æ¬¡é…ç½®
â”œâ”€â”€ round_02_config.json
â”œâ”€â”€ multiround_training.log          # æ€»ä½“æ—¥å¿—
â””â”€â”€ training_state.json              # è®­ç»ƒçŠ¶æ€
```

## æœ€ä½³å®è·µ

### âœ… **æ¨èåšæ³•**

1. **é¦–æ¬¡è®­ç»ƒ**ï¼šä½¿ç”¨é»˜è®¤é…ç½®ï¼Œè§‚å¯Ÿæ•ˆæœ
2. **ç¡¬ä»¶è°ƒä¼˜**ï¼šæ ¹æ® GPU å†…å­˜è°ƒæ•´æ‰¹é‡å¤§å°
3. **æ•°æ®è§„æ¨¡**ï¼šæ ¹æ® Perfect DB å¤§å°è°ƒæ•´ä½ç½®æ•°é‡
4. **æ¢å¤è®­ç»ƒ**ï¼šä½¿ç”¨ `--resume` å‚æ•°æ¢å¤ä¸­æ–­çš„è®­ç»ƒ
5. **ç›‘æ§æ—¥å¿—**ï¼šå…³æ³¨å­¦ä¹ ç‡ç»§æ‰¿å’ŒåŠ¨æ€è°ƒæ•´æƒ…å†µ

### âš ï¸ **æ³¨æ„äº‹é¡¹**

1. **å†…å­˜ç®¡ç†**ï¼šå¤§æ‰¹é‡è®­ç»ƒéœ€è¦è¶³å¤Ÿçš„ GPU å†…å­˜
2. **ç£ç›˜ç©ºé—´**ï¼šæ¯è½®è®­ç»ƒä¼šç”Ÿæˆå¤§é‡æ–‡ä»¶
3. **æ—¶é—´è§„åˆ’**ï¼š6è½®è®­ç»ƒå¯èƒ½éœ€è¦ 12-24 å°æ—¶
4. **æ•°æ®åº“è·¯å¾„**ï¼šç¡®ä¿ Perfect Database è·¯å¾„æ­£ç¡®

## æ€§èƒ½å¯¹æ¯”

| è®­ç»ƒæ–¹å¼ | æ•°æ®å¤šæ ·æ€§ | å‚æ•°ä¼˜åŒ– | è¿ç§»å­¦ä¹  | è®­ç»ƒæ•ˆç‡ | æœ€ç»ˆæ•ˆæœ |
|----------|------------|----------|----------|----------|----------|
| **å¤šè½®+è¿ç§»å­¦ä¹ ** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| å¤šè½®è®­ç»ƒï¼ˆæ— è¿ç§»ï¼‰ | â­â­â­â­â­ | â­â­â­â­ | â­ | â­â­â­ | â­â­â­â­ |
| å•è½®å¤§æ•°æ®é›† | â­â­â­ | â­â­ | â­ | â­â­ | â­â­â­ |

### ğŸ“Š **é¢„æœŸæ€§èƒ½æå‡**

ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼Œå¤šè½®+è¿ç§»å­¦ä¹ é¢„æœŸæå‡ï¼š
- ğŸš€ **è®­ç»ƒé€Ÿåº¦**: 2-3å€åŠ é€Ÿï¼ˆè¿ç§»å­¦ä¹ å‡å°‘æ”¶æ•›æ—¶é—´ï¼‰
- ğŸ“ˆ **æœ€ç»ˆæ€§èƒ½**: 10-25%æå‡ï¼ˆæ›´å¥½çš„ç‰¹å¾å­¦ä¹ ï¼‰
- ğŸ¯ **è®­ç»ƒç¨³å®šæ€§**: æ˜¾è‘—æå‡ï¼ˆé¿å…ä»é›¶å¼€å§‹çš„ä¸ç¨³å®šï¼‰
- â±ï¸ **æ€»è®­ç»ƒæ—¶é—´**: 30-50%å‡å°‘ï¼ˆæ¯è½®æ›´å¿«æ”¶æ•›ï¼‰

## æ•…éšœæ’é™¤

### ğŸ”§ **å¸¸è§é—®é¢˜**

1. **å†…å­˜ä¸è¶³**ï¼šå‡å°æ‰¹é‡å¤§å°æˆ–ä½ç½®æ•°é‡
2. **ç£ç›˜ç©ºé—´ä¸è¶³**ï¼šæ¸…ç†æ—§çš„è®­ç»ƒè¾“å‡º
3. **Perfect DB é”™è¯¯**ï¼šæ£€æŸ¥æ•°æ®åº“è·¯å¾„å’Œæƒé™
4. **æ¢å¤å¤±è´¥**ï¼šæ£€æŸ¥ `training_state.json` æ–‡ä»¶

### ğŸ“ **è·å–å¸®åŠ©**

```bash
# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
python train_multiround.py --help

# è¿è¡Œç¤ºä¾‹
python example_multiround.py

# æŸ¥çœ‹è¯¦ç»†ç”¨æ³•
python example_multiround.py help
```

## æ€»ç»“

å¤šè½®è®­ç»ƒç³»ç»Ÿé€šè¿‡æ™ºèƒ½çš„å‚æ•°ç»§æ‰¿å’ŒåŠ¨æ€è°ƒæ•´ï¼Œæ˜¾è‘—æå‡äº† NNUE æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚ç›¸æ¯”ä¼ ç»Ÿçš„å•è½®å¤§æ•°æ®é›†è®­ç»ƒï¼Œå¤šè½®è®­ç»ƒå…·æœ‰æ›´å¥½çš„æ•°æ®å¤šæ ·æ€§ã€è®­ç»ƒç¨³å®šæ€§å’Œæœ€ç»ˆæ€§èƒ½ã€‚

**æ¨èä½¿ç”¨å¤šè½®è®­ç»ƒè„šæœ¬è¿›è¡Œ NNUE æ¨¡å‹è®­ç»ƒï¼Œä»¥è·å¾—æœ€ä½³çš„è®­ç»ƒæ•ˆæœã€‚**

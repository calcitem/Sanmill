#!/usr/bin/env python3
"""
æµ‹è¯•æœ€æ–°è®­ç»ƒçš„ NNUE æ¨¡å‹åŠ è½½
"""

import os
import sys
import torch
import json

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

def test_latest_model():
    """æµ‹è¯•åŠ è½½æœ€æ–°è®­ç»ƒçš„æ¨¡å‹"""
    print("ğŸ§ª æµ‹è¯•æœ€æ–°è®­ç»ƒçš„ NNUE æ¨¡å‹...")
    
    # åŠ è½½é…ç½®
    config_path = "nnue_pit_config.json"
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    model_path = config["model_path"]
    feature_set_name = config["feature_set"]
    
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
    print(f"ğŸ”§ ç‰¹å¾é›†: {feature_set_name}")
    print(f"ğŸ“ ç‰¹å¾ç»´åº¦: {config['feature_size']}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("\nå¯ç”¨çš„æ¨¡å‹æ–‡ä»¶:")
        for root, dirs, files in os.walk("logs"):
            for file in files:
                if file.endswith('.ckpt'):
                    full_path = os.path.join(root, file)
                    print(f"  - {full_path}")
        return False
    
    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        import model as M
        from features import get_feature_set_from_name
        
        print(f"âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨: {model_path}")
        
        # åˆ›å»ºç‰¹å¾é›†
        feature_set = get_feature_set_from_name(feature_set_name)
        print(f"âœ… ç‰¹å¾é›†åˆ›å»ºæˆåŠŸ: {type(feature_set).__name__}")
        print(f"   å®é™…ç‰¹å¾æ•°: {feature_set.num_real_features}")
        print(f"   è™šæ‹Ÿç‰¹å¾æ•°: {feature_set.num_virtual_features}")
        print(f"   æ€»ç‰¹å¾æ•°: {feature_set.num_features}")
        
        # åŠ è½½æ¨¡å‹
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
        
        nnue_model = M.NNUE.load_from_checkpoint(
            model_path,
            feature_set=feature_set,
            map_location=device
        )
        
        nnue_model.to(device)
        nnue_model.eval()
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        print(f"   æ¨¡å‹ç±»å‹: {type(nnue_model).__name__}")
        print(f"   å‚æ•°æ•°é‡: {sum(p.numel() for p in nnue_model.parameters()):,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in nnue_model.parameters() if p.requires_grad):,}")
        
        # åˆå§‹åŒ– idx_offset (æ¨ç†æ—¶æ‰¹é‡å¤§å°ä¸º1)
        if hasattr(nnue_model, 'layer_stacks') and hasattr(nnue_model.layer_stacks, 'idx_offset'):
            if nnue_model.layer_stacks.idx_offset is None:
                batch_size = 1
                nnue_model.layer_stacks.idx_offset = torch.arange(
                    0,
                    batch_size * nnue_model.layer_stacks.count,
                    nnue_model.layer_stacks.count,
                    device=device
                )
                print(f"âœ… åˆå§‹åŒ– idx_offset (batch_size={batch_size})")
        
        # æµ‹è¯•æ¨¡å‹æ¨ç†
        print("\nğŸ”¬ æµ‹è¯•æ¨¡å‹æ¨ç†...")
        
        # åˆ›å»ºæµ‹è¯•è¾“å…¥ï¼ˆç©ºæ£‹ç›˜çŠ¶æ€ï¼‰
        batch_size = 1
        us = torch.tensor([[1.0]], dtype=torch.float32, device=device)
        them = torch.tensor([[0.0]], dtype=torch.float32, device=device)
        
        # ç©ºçš„ç¨€ç–ç‰¹å¾
        white_indices = torch.zeros((batch_size, 1), dtype=torch.int32, device=device)
        white_values = torch.zeros((batch_size, 1), dtype=torch.float32, device=device)
        black_indices = torch.zeros((batch_size, 1), dtype=torch.int32, device=device)
        black_values = torch.zeros((batch_size, 1), dtype=torch.float32, device=device)
        
        psqt_indices = torch.tensor([0], dtype=torch.long, device=device)
        layer_stack_indices = torch.tensor([0], dtype=torch.long, device=device)
        
        # å‰å‘æ¨ç†
        with torch.no_grad():
            output = nnue_model(
                us, them,
                white_indices, white_values,
                black_indices, black_values,
                psqt_indices, layer_stack_indices
            )
        
        print(f"âœ… æ¨¡å‹æ¨ç†æˆåŠŸ!")
        print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"   è¾“å‡ºå€¼: {output.item():.6f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_latest_model()
    if success:
        print("\nğŸ‰ æ¨¡å‹æµ‹è¯•æˆåŠŸ! å¯ä»¥ä½¿ç”¨ nnue_pit.py è¿›è¡Œå¯¹å¼ˆäº†ã€‚")
        print("\nå¯åŠ¨å‘½ä»¤:")
        print("  python nnue_pit.py --config nnue_pit_config.json --gui")
    else:
        print("\nâŒ æ¨¡å‹æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ¨¡å‹æ–‡ä»¶ã€‚")

#!/usr/bin/env python3
"""
Easy NNUE Training Script - å‚»ç“œåŒ– NNUE è®­ç»ƒå·¥å…·
==================================================

è¿™ä¸ªè„šæœ¬è®©æ–°æ‰‹ä¹Ÿèƒ½è½»æ¾è®­ç»ƒ NNUE æ¨¡å‹ï¼Œæ— éœ€å¤æ‚é…ç½®ã€‚

ä½¿ç”¨æ–¹æ³•:
  python easy_train.py                    # ä½¿ç”¨é»˜è®¤è®¾ç½®è®­ç»ƒ
  python easy_train.py --quick            # å¿«é€Ÿè®­ç»ƒï¼ˆç”¨äºæµ‹è¯•ï¼‰
  python easy_train.py --high-quality     # é«˜è´¨é‡è®­ç»ƒï¼ˆæ›´é•¿æ—¶é—´ï¼‰
  python easy_train.py --gpu              # å¼ºåˆ¶ä½¿ç”¨ GPU
  python easy_train.py --help             # æŸ¥çœ‹å¸®åŠ©
"""

import os
import sys
import json
import time
import subprocess
import argparse
from pathlib import Path
import logging
import io

# Fix Unicode encoding issues on Windows
if sys.platform == 'win32':
    try:
        # Set console encoding to UTF-8
        os.system('chcp 65001 >nul 2>&1')
        # Set stdout and stderr to UTF-8
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    except Exception:
        pass  # Fallback silently if encoding setup fails

try:
    import torch
except ImportError:
    torch = None

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

class EasyNNUETrainer:
    """å‚»ç“œåŒ– NNUE è®­ç»ƒå™¨"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.models_dir = self.project_root / "models"
        self.data_dir = self.project_root / "training_data"
        self.engine_path = self.project_root / "../../sanmill"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.models_dir.mkdir(exist_ok=True)
        self.data_dir.mkdir(exist_ok=True)
        
    def print_banner(self):
        """æ‰“å°æ¬¢è¿æ¨ªå¹…"""
        print("=" * 60)
        print("ğŸ¯ Sanmill NNUE å‚»ç“œåŒ–è®­ç»ƒå·¥å…·")
        print("=" * 60)
        print("è¿™ä¸ªå·¥å…·ä¼šå¸®åŠ©æ‚¨:")
        print("  1. æ£€æŸ¥ç¯å¢ƒå’Œä¾èµ–")
        print("  2. ç”Ÿæˆè®­ç»ƒæ•°æ®")
        print("  3. è®­ç»ƒ NNUE æ¨¡å‹")
        print("  4. éªŒè¯è®­ç»ƒç»“æœ")
        print("  5. å¯åŠ¨ GUI æµ‹è¯•")
        print("=" * 60)
        print()
        
    def check_environment(self):
        """æ£€æŸ¥è®­ç»ƒç¯å¢ƒ"""
        print("ğŸ” æ£€æŸ¥è®­ç»ƒç¯å¢ƒ...")
        
        issues = []
        
        # æ£€æŸ¥ Python ç‰ˆæœ¬
        if sys.version_info < (3, 7):
            issues.append("Python ç‰ˆæœ¬éœ€è¦ 3.7 æˆ–æ›´é«˜")
        else:
            print(f"  âœ… Python {sys.version_info.major}.{sys.version_info.minor}")
            
        # æ£€æŸ¥ä¾èµ–åŒ…
        required_packages = ['torch', 'numpy']
        for package in required_packages:
            try:
                __import__(package)
                print(f"  âœ… {package}")
            except ImportError:
                issues.append(f"ç¼ºå°‘ä¾èµ–åŒ…: {package}")
                
        # æ£€æŸ¥ GPU å¯ç”¨æ€§
        try:
            import torch
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                print(f"  âœ… GPU å¯ç”¨: {gpu_name}")
                self.has_gpu = True
            else:
                print("  âš ï¸  GPU ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU è®­ç»ƒ")
                self.has_gpu = False
        except:
            self.has_gpu = False
            
        # æ£€æŸ¥è®­ç»ƒè„šæœ¬
        if not (self.project_root / "train_nnue.py").exists():
            issues.append("æ‰¾ä¸åˆ° train_nnue.py")
        else:
            print("  âœ… è®­ç»ƒè„šæœ¬")
            
        if issues:
            print("\nâŒ å‘ç°é—®é¢˜:")
            for issue in issues:
                print(f"  - {issue}")
            print("\nè¯·å…ˆè§£å†³è¿™äº›é—®é¢˜:")
            print("  1. å‡çº§ Python: https://www.python.org/downloads/")
            print("  2. å®‰è£…ä¾èµ–: pip install torch numpy matplotlib")
            print("  3. ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•è¿è¡Œè„šæœ¬")
            return False
            
        print("  âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡!")
        return True
        
    def get_user_preferences(self, args):
        """è·å–ç”¨æˆ·åå¥½è®¾ç½®"""
        print("\nâš™ï¸  é…ç½®è®­ç»ƒå‚æ•°...")
        
        if args.quick:
            preset = "quick"
            print("  ğŸ“Š ä½¿ç”¨å¿«é€Ÿè®­ç»ƒé¢„è®¾")
        elif args.high_quality:
            preset = "high_quality"
            print("  ğŸ¯ ä½¿ç”¨é«˜è´¨é‡è®­ç»ƒé¢„è®¾")
        else:
            print("\n  è¯·é€‰æ‹©è®­ç»ƒæ¨¡å¼:")
            print("    1. å¿«é€Ÿè®­ç»ƒ (5-10åˆ†é’Ÿï¼Œé€‚åˆæµ‹è¯•)")
            print("    2. æ ‡å‡†è®­ç»ƒ (30-60åˆ†é’Ÿï¼Œæ¨è)")
            print("    3. é«˜è´¨é‡è®­ç»ƒ (2-4å°æ—¶ï¼Œæœ€ä½³æ•ˆæœ)")
            
            while True:
                choice = input("  è¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
                if choice == "1":
                    preset = "quick"
                    break
                elif choice == "2":
                    preset = "standard"
                    break
                elif choice == "3":
                    preset = "high_quality"
                    break
                else:
                    print("  âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")
                    
        # è®¾å¤‡é€‰æ‹©
        if args.gpu and self.has_gpu:
            device = "cuda"
            print("  ğŸ–¥ï¸  å¼ºåˆ¶ä½¿ç”¨ GPU")
        elif self.has_gpu:
            print(f"\n  æ£€æµ‹åˆ° GPUï¼Œæ˜¯å¦ä½¿ç”¨? (æ¨è)")
            choice = input("  ä½¿ç”¨ GPU è®­ç»ƒ? (y/n): ").strip().lower()
            device = "cuda" if choice in ['y', 'yes', 'æ˜¯', ''] else "cpu"
        else:
            device = "cpu"
            print("  ğŸ’» ä½¿ç”¨ CPU è®­ç»ƒ")
            
        return preset, device
        
    def check_existing_models(self, force=False, auto_backup=False):
        """æ£€æŸ¥ç°æœ‰æ¨¡å‹ï¼Œé˜²æ­¢æ„å¤–è¦†ç›–"""
        print("\nğŸ” æ£€æŸ¥ç°æœ‰è®­ç»ƒæˆæœ...")
        
        # æŸ¥æ‰¾ç°æœ‰æ¨¡å‹
        existing_models = []
        patterns = ["nnue_model*.bin", "nnue_model*.pth", "models/nnue_model*.bin", "models/nnue_model*.pth"]
        
        for pattern in patterns:
            for model_file in self.project_root.glob(pattern):
                if model_file.is_file():
                    existing_models.append(model_file)
        
        if existing_models:
            print(f"  å‘ç° {len(existing_models)} ä¸ªç°æœ‰æ¨¡å‹:")
            for model in existing_models:
                size = model.stat().st_size / 1024
                mtime = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(model.stat().st_mtime))
                print(f"    ğŸ“ {model} ({size:.1f} KB, {mtime})")
            
            if force:
                print("  âš ï¸  å¼ºåˆ¶æ¨¡å¼ï¼šè·³è¿‡å¤‡ä»½ï¼Œç›´æ¥ç»§ç»­è®­ç»ƒ")
                return True
            elif auto_backup:
                print("  ğŸ’¾ è‡ªåŠ¨å¤‡ä»½æ¨¡å¼ï¼šè‡ªåŠ¨å¤‡ä»½ç°æœ‰æ¨¡å‹")
                self.backup_existing_models(existing_models)
                return True
            else:
                print("\nâš ï¸  ç»§ç»­è®­ç»ƒå°†å¯èƒ½è¦†ç›–ç°æœ‰æ¨¡å‹ï¼")
                print("   ğŸ’¡ æ³¨æ„ï¼šç»§ç»­è®­ç»ƒä¼šç”Ÿæˆæ–°çš„è®­ç»ƒæ•°æ®å¹¶è¦†ç›–ç°æœ‰æ¨¡å‹")
                print("   ğŸ“¦ æ—§çš„è®­ç»ƒæ•°æ®ä¼šè‡ªåŠ¨å¤‡ä»½ä¸ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶")
                print("   å»ºè®®é€‰æ‹©:")
                print("   1. å¤‡ä»½ç°æœ‰æ¨¡å‹ (æ¨è)")
                print("   2. ç»§ç»­è®­ç»ƒ (ç”Ÿæˆæ–°æ•°æ®ï¼Œè‡ªåŠ¨å¤‡ä»½æ—§æ•°æ®)")
                print("   3. å–æ¶ˆè®­ç»ƒ")
                
                while True:
                    choice = input("   è¯·é€‰æ‹© (1-3): ").strip()
                    if choice == "1":
                        self.backup_existing_models(existing_models)
                        break
                    elif choice == "2":
                        print("   âš ï¸  é€‰æ‹©ç»§ç»­ï¼Œç°æœ‰æ¨¡å‹å¯èƒ½è¢«è¦†ç›–")
                        print("   ğŸ“¦ æ—§çš„è®­ç»ƒæ•°æ®å°†è¢«è‡ªåŠ¨å¤‡ä»½")
                        break
                    elif choice == "3":
                        print("   âœ… è®­ç»ƒå·²å–æ¶ˆï¼Œç°æœ‰æ¨¡å‹å®‰å…¨")
                        return False
                    else:
                        print("   âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1ã€2 æˆ– 3")
        else:
            print("  âœ… æ²¡æœ‰å‘ç°ç°æœ‰æ¨¡å‹")
        
        return True
    
    def backup_existing_models(self, existing_models):
        """å¤‡ä»½ç°æœ‰æ¨¡å‹"""
        print("\nğŸ’¾ å¤‡ä»½ç°æœ‰æ¨¡å‹...")
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        backup_dir = self.project_root / "model_backups" / time.strftime("%Y%m%d_%H%M%S")
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        backed_up = 0
        for model_file in existing_models:
            try:
                backup_path = backup_dir / model_file.name
                import shutil
                shutil.copy2(model_file, backup_path)
                backed_up += 1
                print(f"    âœ… {model_file.name} -> {backup_path}")
            except Exception as e:
                print(f"    âŒ å¤‡ä»½å¤±è´¥ {model_file.name}: {e}")
        
        if backed_up > 0:
            print(f"  âœ… æˆåŠŸå¤‡ä»½ {backed_up} ä¸ªæ¨¡å‹åˆ°: {backup_dir}")
            
            # åˆ›å»ºæ¢å¤è„šæœ¬
            self.create_restore_script(backup_dir, existing_models)
        else:
            print("  âŒ æ²¡æœ‰æ¨¡å‹è¢«æˆåŠŸå¤‡ä»½")
    
    def create_restore_script(self, backup_dir, original_models):
        """åˆ›å»ºæ¨¡å‹æ¢å¤è„šæœ¬"""
        restore_script = backup_dir / "restore_models.py"
        
        script_content = f'''#!/usr/bin/env python3
"""
æ¨¡å‹æ¢å¤è„šæœ¬
è‡ªåŠ¨ç”Ÿæˆäº: {time.strftime("%Y-%m-%d %H:%M:%S")}
"""

import shutil
import os
from pathlib import Path

def restore_models():
    """æ¢å¤å¤‡ä»½çš„æ¨¡å‹"""
    backup_dir = Path(__file__).parent
    project_root = backup_dir.parent.parent
    
    print("ğŸ”„ æ¢å¤å¤‡ä»½çš„æ¨¡å‹...")
    
    restore_mapping = {{'''
        
        for model in original_models:
            script_content += f'''
        "{model.name}": "{model.relative_to(self.project_root)}",'''
        
        script_content += f'''
    }}
    
    restored = 0
    for backup_name, original_path in restore_mapping.items():
        backup_file = backup_dir / backup_name
        original_file = project_root / original_path
        
        if backup_file.exists():
            try:
                # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                original_file.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(backup_file, original_file)
                print(f"  âœ… æ¢å¤: {{backup_name}} -> {{original_path}}")
                restored += 1
            except Exception as e:
                print(f"  âŒ æ¢å¤å¤±è´¥ {{backup_name}}: {{e}}")
        else:
            print(f"  âš ï¸  å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {{backup_name}}")
    
    print(f"\\nâœ… æ¢å¤å®Œæˆï¼Œå…±æ¢å¤ {{restored}} ä¸ªæ¨¡å‹")

if __name__ == '__main__':
    restore_models()
'''
        
        with open(restore_script, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        print(f"    ğŸ“œ åˆ›å»ºæ¢å¤è„šæœ¬: {restore_script}")
        print(f"    ğŸ’¡ å¦‚éœ€æ¢å¤æ¨¡å‹ï¼Œè¿è¡Œ: python {restore_script}")
    
    def check_resume_training(self):
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¢å¤è®­ç»ƒ"""
        print("\nğŸ”„ æ£€æŸ¥è®­ç»ƒæ¢å¤é€‰é¡¹...")
        
        # æŸ¥æ‰¾æ£€æŸ¥ç‚¹æ–‡ä»¶
        checkpoint_patterns = ["checkpoint*.pth", "*.checkpoint", "models/checkpoint*.pth"]
        checkpoints = []
        
        for pattern in checkpoint_patterns:
            for ckpt_file in self.project_root.glob(pattern):
                if ckpt_file.is_file():
                    checkpoints.append(ckpt_file)
        
        if checkpoints:
            print(f"  å‘ç° {len(checkpoints)} ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶:")
            for ckpt in checkpoints:
                size = ckpt.stat().st_size / 1024
                mtime = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(ckpt.stat().st_mtime))
                print(f"    ğŸ”„ {ckpt} ({size:.1f} KB, {mtime})")
            
            print("\n  æ˜¯å¦ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼Ÿ")
            print("    y - æ¢å¤è®­ç»ƒ (ç»§ç»­ä¹‹å‰çš„è¿›åº¦)")
            print("    n - é‡æ–°å¼€å§‹ (å°†åˆ›å»ºæ–°çš„è®­ç»ƒ)")
            
            choice = input("  æ¢å¤è®­ç»ƒ? (y/n): ").strip().lower()
            if choice in ['y', 'yes', 'æ˜¯']:
                # é€‰æ‹©æœ€æ–°çš„æ£€æŸ¥ç‚¹
                latest_checkpoint = max(checkpoints, key=lambda f: f.stat().st_mtime)
                print(f"  âœ… å°†ä»æ£€æŸ¥ç‚¹æ¢å¤: {latest_checkpoint}")
                return str(latest_checkpoint)
            else:
                print("  âœ… å°†é‡æ–°å¼€å§‹è®­ç»ƒ")
                # å¤‡ä»½æ£€æŸ¥ç‚¹æ–‡ä»¶
                self.backup_checkpoints(checkpoints)
        else:
            print("  âœ… æ²¡æœ‰å‘ç°æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œå°†è¿›è¡Œå…¨æ–°è®­ç»ƒ")
        
        return None
    
    def backup_checkpoints(self, checkpoints):
        """å¤‡ä»½æ£€æŸ¥ç‚¹æ–‡ä»¶"""
        if not checkpoints:
            return
            
        print(f"  ğŸ’¾ å¤‡ä»½ {len(checkpoints)} ä¸ªæ£€æŸ¥ç‚¹æ–‡ä»¶...")
        backup_dir = self.project_root / "checkpoint_backups" / time.strftime("%Y%m%d_%H%M%S")
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        for ckpt in checkpoints:
            try:
                backup_path = backup_dir / ckpt.name
                import shutil
                shutil.copy2(ckpt, backup_path)
                print(f"    âœ… {ckpt.name} -> {backup_path}")
            except Exception as e:
                print(f"    âŒ å¤‡ä»½å¤±è´¥ {ckpt.name}: {e}")

    def load_config_file(self, config_path):
        """åŠ è½½å¤–éƒ¨é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼"""
        try:
            config_file = Path(config_path)
            if not config_file.exists():
                print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
                return None
                
            print(f"\nğŸ“ åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
            
            with open(config_file, 'r', encoding='utf-8') as f:
                raw_config = json.load(f)
            
            # æ£€æµ‹é…ç½®æ–‡ä»¶æ ¼å¼
            if 'training' in raw_config:
                # Easy train æ ¼å¼
                config = self._validate_easy_train_config(raw_config)
            else:
                # Train_nnue.py æ ¼å¼ï¼Œéœ€è¦è½¬æ¢
                config = self._convert_train_nnue_config(raw_config)
            
            if config is None:
                return None
            
            # ç”Ÿæˆå”¯ä¸€çš„è¾“å‡ºæ–‡ä»¶åï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
            if 'output' not in config:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                config['output'] = f"models/nnue_model_custom_{timestamp}.bin"
                
            if 'checkpoint_path' not in config:
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                config['checkpoint_path'] = f"models/checkpoint_custom_{timestamp}.pth"
            
            print(f"  âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            print(f"  ğŸ“Š è®­ç»ƒè½®æ•°: {config['training']['epochs']}")
            print(f"  ğŸ“¦ æ‰¹æ¬¡å¤§å°: {config['training']['batch_size']}")
            print(f"  ğŸ¯ å­¦ä¹ ç‡: {config['training']['lr']}")
            print(f"  ğŸ§  éšè—å±‚å¤§å°: {config['training']['hidden_size']}")
            print(f"  ğŸ”„ ç®¡é“æ¨¡å¼: {'æ˜¯' if config.get('pipeline', False) else 'å¦'}")
            
            return config
            
        except json.JSONDecodeError as e:
            print(f"âŒ é…ç½®æ–‡ä»¶ JSON æ ¼å¼é”™è¯¯: {e}")
            return None
        except Exception as e:
            print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return None

    def _validate_easy_train_config(self, config):
        """éªŒè¯ easy_train æ ¼å¼çš„é…ç½®æ–‡ä»¶"""
        # éªŒè¯è®­ç»ƒé…ç½®å¿…éœ€å­—æ®µ
        training_required = ['epochs', 'batch_size', 'lr']
        for field in training_required:
            if field not in config['training']:
                print(f"âŒ è®­ç»ƒé…ç½®ç¼ºå°‘å¿…éœ€å­—æ®µ: training.{field}")
                return None
        
        # è®¾ç½®é»˜è®¤å€¼
        config.setdefault('pipeline', False)
        config.setdefault('device', 'auto')
        config.setdefault('plot', True)
        config.setdefault('save_checkpoint', True)
        
        # è®¾ç½®è®­ç»ƒé…ç½®é»˜è®¤å€¼
        training = config['training']
        training.setdefault('hidden_size', 256)
        training.setdefault('val_split', 0.15)
        
        return config

    def _convert_train_nnue_config(self, raw_config):
        """å¤„ç† train_nnue.py æ ¼å¼çš„é…ç½®æ–‡ä»¶ï¼ˆç®¡é“æ¨¡å¼ç›´æ¥ä¼ é€’ï¼‰"""
        try:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            required_fields = ['epochs', 'batch-size', 'lr']
            for field in required_fields:
                if field not in raw_config:
                    print(f"âŒ é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                    return None
            
            # å¯¹äºç®¡é“æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹é…ç½®ï¼Œåªåšæœ€å°è½¬æ¢ä»¥å…¼å®¹æ˜¾ç¤º
            if raw_config.get('pipeline', False):
                # ç®¡é“æ¨¡å¼ï¼šä¿æŒåŸå§‹æ ¼å¼ï¼Œtrain_nnue.py ä¼šç›´æ¥å¤„ç†
                config = raw_config.copy()
                
                # å¼ºåˆ¶è¦æ±‚å¼•æ“è®¾ç½®ä¸º null
                if 'engine' not in config:
                    print(f"âŒ é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€å­—æ®µ: engine")
                    print(f"   è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ : \"engine\": null")
                    return None
                elif config['engine'] is not None:
                    print(f"âŒ é…ç½®æ–‡ä»¶ä¸­ engine å¿…é¡»è®¾ç½®ä¸º null")
                    print(f"   å½“å‰å€¼: {config['engine']}")
                    print(f"   è¯·ä¿®æ”¹ä¸º: \"engine\": null")
                    return None
                else:
                    print(f"  âœ… å¼•æ“å·²æ­£ç¡®è®¾ç½®ä¸º nullï¼Œå°†ä½¿ç”¨ç›´æ¥ Perfect DB æ•°æ®ç”Ÿæˆ")
                
                # æ·»åŠ ç”¨äºæ˜¾ç¤ºçš„ training ä¿¡æ¯
                config['training'] = {
                    'epochs': raw_config['epochs'],
                    'batch_size': raw_config['batch-size'],
                    'lr': raw_config['lr'],
                    'hidden_size': raw_config.get('hidden-size', 256),
                    'val_split': raw_config.get('val-split', 0.15)
                }
                
                print(f"  ğŸ”„ ä¿æŒ train_nnue.py ç®¡é“æ¨¡å¼é…ç½®æ ¼å¼")
                return config
            else:
                # éç®¡é“æ¨¡å¼ä¹Ÿå¿…é¡»æ£€æŸ¥ engine è®¾ç½®
                if 'engine' not in raw_config:
                    print(f"âŒ é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…éœ€å­—æ®µ: engine")
                    print(f"   è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ : \"engine\": null")
                    return None
                elif raw_config['engine'] is not None:
                    print(f"âŒ é…ç½®æ–‡ä»¶ä¸­ engine å¿…é¡»è®¾ç½®ä¸º null")
                    print(f"   å½“å‰å€¼: {raw_config['engine']}")
                    print(f"   è¯·ä¿®æ”¹ä¸º: \"engine\": null")
                    return None
                
                # éç®¡é“æ¨¡å¼ï¼šè½¬æ¢ä¸º easy_train æ ¼å¼
                config = {
                    'pipeline': False,
                    'device': raw_config.get('device', 'auto'),
                    'plot': raw_config.get('plot', True),
                    'save_checkpoint': True,
                    'checkpoint_interval': 10,
                    'training': {
                        'epochs': raw_config['epochs'],
                        'batch_size': raw_config['batch-size'],
                        'lr': raw_config['lr'],
                        'hidden_size': raw_config.get('hidden-size', 256),
                        'val_split': raw_config.get('val-split', 0.15)
                    }
                }
                
                # è®¾ç½®æ•°æ®æ–‡ä»¶
                if 'data' in raw_config:
                    config['data'] = raw_config['data']
                if 'output' in raw_config:
                    config['output'] = raw_config['output']
                
                print(f"  âœ… å¼•æ“å·²æ­£ç¡®è®¾ç½®ä¸º nullï¼Œå·²è½¬æ¢ä¸º easy_train æ ¼å¼é…ç½®")
                return config
            
        except Exception as e:
            print(f"âŒ è½¬æ¢é…ç½®æ–‡ä»¶æ ¼å¼æ—¶å‡ºé”™: {e}")
            return None

    def create_training_config(self, preset, device):
        """åˆ›å»ºè®­ç»ƒé…ç½®"""
        print(f"\nğŸ“ åˆ›å»º {preset} è®­ç»ƒé…ç½®...")
        
        configs = {
            "quick": {
                "description": "å¿«é€Ÿè®­ç»ƒé…ç½® - ç”¨äºæµ‹è¯•å’Œå­¦ä¹ ",
                "pipeline": True,
                "data_generation": {
                    "positions": 1000,
                    "threads": 2,
                    "timeout": 5
                },
                "training": {
                    "epochs": 10,
                    "batch_size": 512,
                    "lr": 0.003,
                    "hidden_size": 128,
                    "val_split": 0.2
                }
            },
            "standard": {
                "description": "æ ‡å‡†è®­ç»ƒé…ç½® - å¹³è¡¡æ•ˆæœå’Œæ—¶é—´",
                "pipeline": True,
                "data_generation": {
                    "positions": 10000,
                    "threads": 4,
                    "timeout": 10
                },
                "training": {
                    "epochs": 100,
                    "batch_size": 2048,
                    "lr": 0.002,
                    "hidden_size": 256,
                    "val_split": 0.15
                }
            },
            "high_quality": {
                "description": "é«˜è´¨é‡è®­ç»ƒé…ç½® - è¿½æ±‚æœ€ä½³æ•ˆæœ",
                "pipeline": True,
                "data_generation": {
                    "positions": 50000,
                    "threads": 8,
                    "timeout": 20
                },
                "training": {
                    "epochs": 300,
                    "batch_size": 4096,
                    "lr": 0.002,
                    "hidden_size": 256,  # Changed from 512 to 256 for compatibility with nnue_pit.py
                    "val_split": 0.1
                }
            }
        }
        
        config = configs[preset].copy()
        
        # æ ¹æ®è®¾å¤‡è°ƒæ•´é…ç½®
        if device == "cpu":
            # CPU ä¼˜åŒ–
            config["training"]["batch_size"] = min(config["training"]["batch_size"], 1024)
            config["data_generation"]["threads"] = min(config["data_generation"]["threads"], 2)
            config["training"]["hidden_size"] = min(config["training"]["hidden_size"], 256)
            print("  ğŸ”§ å·²é’ˆå¯¹ CPU ä¼˜åŒ–é…ç½®")
        else:
            print("  ğŸš€ å·²é’ˆå¯¹ GPU ä¼˜åŒ–é…ç½®")
            
        config["device"] = device
        
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å”¯ä¸€è¾“å‡ºæ–‡ä»¶åï¼Œé¿å…è¦†ç›–
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        config["output"] = f"models/nnue_model_{preset}_{timestamp}.bin"
        config["checkpoint_path"] = f"models/checkpoint_{preset}_{timestamp}.pth"
        
        # Perfect æ•°æ®åº“é…ç½® (ç°åœ¨ç›´æ¥ä½¿ç”¨ Perfect DB DLLï¼Œä¸éœ€è¦å¼•æ“)
        config["engine"] = None  # ä¸å†éœ€è¦å¼•æ“
        config["perfect_db"] = "E:\\Malom\\Malom_Standard_Ultra-strong_1.1.0\\Std_DD_89adjusted"
        
        config["plot"] = True
        config["plot_interval"] = 25       # å‡å°‘å›¾è¡¨æ›´æ–°é¢‘ç‡ï¼Œé¿å…é˜»å¡
        config["save_checkpoint"] = True
        config["checkpoint_interval"] = 10  # æ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
        config["backup_models"] = True      # è‡ªåŠ¨å¤‡ä»½ç°æœ‰æ¨¡å‹
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        config_path = self.project_root / f"easy_train_{preset}_config.json"
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
            
        print(f"  âœ… é…ç½®å·²ä¿å­˜: {config_path}")
        return config_path, config
        
    def estimate_training_time(self, config):
        """ä¼°ç®—è®­ç»ƒæ—¶é—´"""
        preset_times = {
            "quick": (5, 10),
            "standard": (30, 60),
            "high_quality": (120, 240)
        }
        
        for preset, (min_time, max_time) in preset_times.items():
            if preset in str(config):
                device_factor = 0.3 if config.get("device") == "cuda" else 1.0
                estimated_min = int(min_time * device_factor)
                estimated_max = int(max_time * device_factor)
                
                print(f"\nâ±ï¸  é¢„è®¡è®­ç»ƒæ—¶é—´: {estimated_min}-{estimated_max} åˆ†é’Ÿ")
                return estimated_min, estimated_max
                
        return 30, 60
        
    def run_training(self, config_path):
        """è¿è¡Œè®­ç»ƒï¼ˆåŒ…æ‹¬æ•°æ®ç”Ÿæˆå’Œæ¨¡å‹è®­ç»ƒï¼‰"""
        
        # è¯»å–é…ç½®æ–‡ä»¶æ£€æŸ¥æ˜¯å¦éœ€è¦æ•°æ®ç”Ÿæˆ
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å–é…ç½®æ–‡ä»¶: {e}")
            return False
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç®¡é“æ¨¡å¼ï¼ˆéœ€è¦æ•°æ®ç”Ÿæˆï¼‰
        is_pipeline = config.get('pipeline', False)
        updated_config_path = config_path
        
        if is_pipeline:
            print(f"\nğŸ”„ æ£€æµ‹åˆ°ç®¡é“æ¨¡å¼ï¼Œå°†ä½¿ç”¨ train_nnue.py çš„å®Œæ•´ç®¡é“åŠŸèƒ½...")
            print("  ğŸ“Š æ•°æ®ç”Ÿæˆå’Œæ¨¡å‹è®­ç»ƒå°†ç”± train_nnue.py ç»Ÿä¸€å¤„ç†")
            print(f"\nğŸš€ å¼€å§‹å®Œæ•´ç®¡é“è®­ç»ƒ...")
        else:
            print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ...")
            
        print("  è®­ç»ƒè¿‡ç¨‹ä¸­è¯·ä¸è¦å…³é—­çª—å£")
        print("  æ‚¨å¯ä»¥é€šè¿‡æŸ¥çœ‹æ—¥å¿—æ¥ç›‘æ§è¿›åº¦")
        print()
        
        # æ„å»ºè®­ç»ƒå‘½ä»¤
        cmd = [
            sys.executable, 
            "train_nnue.py", 
            "--config", str(updated_config_path)
        ]
        
        # å¦‚æœæ˜¯ç®¡é“æ¨¡å¼ï¼Œæ·»åŠ å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ•°æ®å‚æ•°
        # è¿™ç¡®ä¿æ¯æ¬¡"ç»§ç»­è®­ç»ƒ"éƒ½ä¼šç”Ÿæˆæ–°çš„è®­ç»ƒæ•°æ®
        if is_pipeline:
            cmd.append("--force-regenerate")
        
        print(f"  æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        print("  " + "=" * 50)
        
        try:
            # è¿è¡Œè®­ç»ƒ
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                universal_newlines=True,
                bufsize=1
            )
            
            # å®æ—¶æ˜¾ç¤ºè¾“å‡º
            for line in process.stdout:
                print(f"  {line.rstrip()}")
                
            process.wait()
            
            if process.returncode == 0:
                print("  " + "=" * 50)
                print("  âœ… è®­ç»ƒå®Œæˆ!")
                
                # Auto-generate training visualization plots
                try:
                    from auto_plot import auto_generate_plots
                    
                    # Look for CSV files in common locations
                    csv_locations = [
                        self.project_root / "nnue_output" / "plots" / "training_metrics.csv",  # Primary location
                        self.project_root / "plots" / "training_metrics.csv",  # Legacy fallback
                        self.project_root / "training_metrics.csv"  # Root fallback
                    ]
                    
                    csv_found = None
                    for csv_path in csv_locations:
                        if csv_path.exists():
                            csv_found = csv_path
                            break
                    
                    if csv_found:
                        print(f"\nğŸ“ˆ ç”Ÿæˆè®­ç»ƒå¯è§†åŒ–å›¾è¡¨...")
                        success = auto_generate_plots(
                            csv_file=str(csv_found),
                            output_dir=str(csv_found.parent),
                            comprehensive_only=True,  # Only generate main plot for faster execution
                            max_plot_points=10  # Optimize plotting performance
                        )
                        if success:
                            print(f"  âœ… è®­ç»ƒå›¾è¡¨å·²ç”Ÿæˆåˆ°: {csv_found.parent}")
                            print(f"  ğŸ” å¯æŸ¥çœ‹ä»¥ä¸‹æ–‡ä»¶:")
                            print(f"     â€¢ training_analysis_comprehensive.png")
                            print(f"     â€¢ loss_convergence_analysis.png") 
                            print(f"     â€¢ performance_summary.png")
                        else:
                            print(f"  âš ï¸  å›¾è¡¨ç”Ÿæˆå¤±è´¥")
                    else:
                        print(f"  â„¹ï¸  æœªæ‰¾åˆ°è®­ç»ƒ CSV æ•°æ®ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
                        
                except Exception as e:
                    print(f"  âš ï¸  è‡ªåŠ¨å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
                
                return True
            else:
                print("  " + "=" * 50)
                print(f"  âŒ è®­ç»ƒå¤±è´¥ï¼Œè¿”å›ç : {process.returncode}")
                return False
                
        except KeyboardInterrupt:
            print("\n  â¹ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
            process.terminate()
            return False
        except Exception as e:
            print(f"  âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
            return False


    def find_trained_model(self, show_details=True):
        """æŸ¥æ‰¾è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä¼˜å…ˆæ£€æŸ¥ models ç›®å½•"""
        if show_details:
            print("\nğŸ” æŸ¥æ‰¾å·²è®­ç»ƒçš„æ¨¡å‹...")
        
        found_models = []
        
        # 1. ä¼˜å…ˆæ£€æŸ¥ models ç›®å½•ï¼ˆæ¨èä½ç½®ï¼‰
        if show_details:
            print("  ğŸ“ æ£€æŸ¥ models/ ç›®å½•...")
        model_files = list(self.models_dir.glob("*.bin")) + list(self.models_dir.glob("*.pth"))
        if model_files:
            for f in model_files:
                found_models.append(('models', f))
                if show_details:
                    size_mb = f.stat().st_size / (1024 * 1024)
                    mtime = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(f.stat().st_mtime))
                    print(f"    âœ… {f.name} ({size_mb:.1f}MB, ä¿®æ”¹æ—¶é—´: {mtime})")
        
        # 2. æ£€æŸ¥ nnue_output ç›®å½•ï¼ˆæ—§çš„ç®¡é“è¾“å‡ºï¼‰
        if show_details:
            print("  ğŸ“ æ£€æŸ¥ nnue_output/ ç›®å½•...")
        nnue_output_dir = self.project_root / "nnue_output"
        if nnue_output_dir.exists():
            output_files = list(nnue_output_dir.glob("*.bin")) + list(nnue_output_dir.glob("*.pth"))
            if output_files:
                for f in output_files:
                    found_models.append(('nnue_output', f))
                    if show_details:
                        size_mb = f.stat().st_size / (1024 * 1024)
                        mtime = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(f.stat().st_mtime))
                        print(f"    âš ï¸  {f.name} ({size_mb:.1f}MB, ä¿®æ”¹æ—¶é—´: {mtime}) [æ—§ä½ç½®]")
            elif show_details:
                print("    ğŸ“­ æ— æ¨¡å‹æ–‡ä»¶")
        elif show_details:
            print("    ğŸ“­ ç›®å½•ä¸å­˜åœ¨")
        
        # 3. æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•
        if show_details:
            print("  ğŸ“ æ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•...")
        root_files = list(self.project_root.glob("nnue_model*.bin")) + list(self.project_root.glob("nnue_model*.pth"))
        if root_files:
            for f in root_files:
                found_models.append(('root', f))
                if show_details:
                    size_mb = f.stat().st_size / (1024 * 1024)
                    mtime = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(f.stat().st_mtime))
                    print(f"    âš ï¸  {f.name} ({size_mb:.1f}MB, ä¿®æ”¹æ—¶é—´: {mtime}) [æ ¹ç›®å½•]")
        elif show_details:
            print("    ğŸ“­ æ— æ¨¡å‹æ–‡ä»¶")
            
        if not found_models:
            if show_details:
                print("  âŒ æœªæ‰¾åˆ°ä»»ä½•æ¨¡å‹æ–‡ä»¶")
            return None
            
        # ä¼˜å…ˆé€‰æ‹© models ç›®å½•ä¸­çš„æœ€æ–°æ–‡ä»¶ï¼Œå…¶æ¬¡æ˜¯å…¶ä»–ä½ç½®
        models_dir_files = [f for loc, f in found_models if loc == 'models']
        if models_dir_files:
            latest_model = max(models_dir_files, key=lambda f: f.stat().st_mtime)
            if show_details:
                print(f"  âœ… é€‰æ‹© models/ ç›®å½•ä¸­çš„æœ€æ–°æ¨¡å‹: {latest_model.name}")
        else:
            # å¦‚æœ models ç›®å½•æ²¡æœ‰æ–‡ä»¶ï¼Œé€‰æ‹©å…¶ä»–ä½ç½®çš„æœ€æ–°æ–‡ä»¶
            latest_model = max([f for loc, f in found_models], key=lambda f: f.stat().st_mtime)
            if show_details:
                print(f"  âœ… é€‰æ‹©æœ€æ–°æ¨¡å‹: {latest_model} (å»ºè®®ç§»åŠ¨åˆ° models/ ç›®å½•)")
                
        return latest_model
    
    def should_load_model(self, load_model_setting, checkpoint_dir=None):
        """
        æ ¹æ®è®¾ç½®å’Œæ£€æŸ¥ç‚¹ç›®å½•çŠ¶æ€å†³å®šæ˜¯å¦åŠ è½½æ¨¡å‹
        æ ¹æ®è®°å¿†è¦æ±‚ï¼šæ£€æŸ¥ checkpoint ç›®å½•ä¸­æ˜¯å¦æœ‰ä»»ä½• .tar æ–‡ä»¶
        - å¦‚æœæ²¡æœ‰ .tar æ–‡ä»¶ï¼Œå¿½ç•¥ load_model è®¾ç½®
        - å¦‚æœæœ‰ .tar æ–‡ä»¶ï¼Œå°Šé‡ load_model è®¾ç½®ï¼Œä½†è¦æ±‚ç›®æ ‡æ–‡ä»¶å­˜åœ¨
        """
        if checkpoint_dir is None:
            checkpoint_dir = self.models_dir
            
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½• .tar æ–‡ä»¶
        tar_files = list(checkpoint_dir.glob("*.tar"))
        
        if not tar_files:
            print("  ğŸ“­ æ£€æŸ¥ç‚¹ç›®å½•ä¸­æ—  .tar æ–‡ä»¶ï¼Œè·³è¿‡æ¨¡å‹åŠ è½½")
            return False, None
            
        print(f"  ğŸ“¦ æ‰¾åˆ° {len(tar_files)} ä¸ª .tar æ£€æŸ¥ç‚¹æ–‡ä»¶")
        for tar_file in tar_files:
            size_mb = tar_file.stat().st_size / (1024 * 1024)
            mtime = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(tar_file.stat().st_mtime))
            print(f"    ğŸ“¦ {tar_file.name} ({size_mb:.1f}MB, {mtime})")
        
        if not load_model_setting:
            print("  â­ï¸  load_model è®¾ç½®ä¸º Falseï¼Œè·³è¿‡åŠ è½½")
            return False, None
            
        # å°Šé‡ load_model è®¾ç½®ï¼Œä½†æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        model_file = self.find_trained_model(show_details=False)
        if model_file is None:
            print("  âŒ load_model ä¸º True ä½†æœªæ‰¾åˆ°å¯åŠ è½½çš„æ¨¡å‹æ–‡ä»¶")
            return False, None
            
        print(f"  âœ… å°†åŠ è½½æ¨¡å‹: {model_file}")
        return True, model_file
        
    def validate_model(self, model_path):
        """éªŒè¯è®­ç»ƒçš„æ¨¡å‹"""
        print(f"\nğŸ” éªŒè¯è®­ç»ƒçš„æ¨¡å‹: {model_path}")
        
        try:
            # ç®€åŒ–éªŒè¯ï¼šåªæ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§å’Œå¤§å°
            if not model_path.exists():
                print(f"  âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                return False
                
            model_size = model_path.stat().st_size
            if model_size == 0:
                print(f"  âŒ æ¨¡å‹æ–‡ä»¶ä¸ºç©º: {model_path}")
                return False
                
            print(f"  âœ… æ¨¡å‹æ–‡ä»¶éªŒè¯æˆåŠŸ ({model_size} bytes)")
            
            # å¿«é€Ÿæ¨¡å‹åŠ è½½æµ‹è¯•ï¼ˆé¿å…å¯¼å…¥å¯èƒ½è§¦å‘ç»˜å›¾çš„æ¨¡å—ï¼‰
            try:
                # å°è¯•åŠ è½½æ¨¡å‹ï¼ˆä½†é¿å…å¯¼å…¥æ•´ä¸ª nnue_pit æ¨¡å—ï¼‰
                print("  â„¹ï¸  æ¨¡å‹å†…å®¹éªŒè¯å·²ç®€åŒ–ä»¥é¿å…é¢å¤–çš„ç»˜å›¾è°ƒç”¨")
                print("  âœ… åŸºç¡€éªŒè¯é€šè¿‡")
                return True
                
            except Exception as load_error:
                print(f"  âš ï¸  æ¨¡å‹åŠ è½½æµ‹è¯•è·³è¿‡: {load_error}")
                print("  âœ… æ–‡ä»¶éªŒè¯é€šè¿‡ï¼ˆå¯èƒ½ä»ç„¶å¯ç”¨ï¼‰")
                return True
            
        except Exception as e:
            print(f"  âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
            return False
            
    def launch_gui_test(self, model_path):
        """å¯åŠ¨ GUI æµ‹è¯•"""
        print(f"\nğŸ® å¯åŠ¨ GUI æµ‹è¯•...")
        print("ğŸš€ Checking GUI environment...")
        
        try:
            import tkinter
            print("ğŸš€ GUI environment available")
        except ImportError:
            print("ğŸš€ GUI environment not available, skipping GUI test")
            return
            
        print("ğŸš€ Prompting user for GUI test choice...")
        print("  æ˜¯å¦ç°åœ¨å¯åŠ¨ GUI æ¥æµ‹è¯•æ‚¨çš„æ¨¡å‹?")
        choice = input("  å¯åŠ¨ GUI æµ‹è¯•? (y/n): ").strip().lower()
        print(f"ğŸš€ User choice: '{choice}'")
        
        if choice in ['y', 'yes', 'æ˜¯', '']:
            print("ğŸš€ User chose to start GUI test")
            try:
                cmd = [sys.executable, "nnue_pit.py", "--model", str(model_path), "--gui", "--first", "human"]
                print(f"ğŸš€ Starting GUI with command: {' '.join(cmd)}")
                print("ğŸš€ About to run subprocess...")
                subprocess.run(cmd)
                print("ğŸš€ Subprocess completed")
            except Exception as e:
                print(f"ğŸš€ GUI launch failed: {e}")
                print("  æ‚¨å¯ä»¥æ‰‹åŠ¨è¿è¡Œ:")
                print(f"    python nnue_pit.py --model {model_path} --gui")
        else:
            print("ğŸš€ User chose to skip GUI test")
            print("  è·³è¿‡ GUI æµ‹è¯•")
            print("  æ‚¨å¯ä»¥ç¨åæ‰‹åŠ¨å¯åŠ¨:")
            print(f"    python nnue_pit.py --model {model_path} --gui")
            
    def cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        temp_patterns = ["easy_train_*_config.json", "training_data_*.txt", "*.tmp"]
        
        print("\nğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        cleaned = 0
        
        for pattern in temp_patterns:
            for temp_file in self.project_root.glob(pattern):
                try:
                    temp_file.unlink()
                    cleaned += 1
                except:
                    pass
                    
        if cleaned > 0:
            print(f"  âœ… æ¸…ç†äº† {cleaned} ä¸ªä¸´æ—¶æ–‡ä»¶")
        else:
            print("  âœ… æ²¡æœ‰éœ€è¦æ¸…ç†çš„ä¸´æ—¶æ–‡ä»¶")
            
    def show_summary(self, model_path, training_time):
        """æ˜¾ç¤ºè®­ç»ƒæ€»ç»“"""
        print("\n" + "=" * 60)
        print("ğŸ‰ è®­ç»ƒå®Œæˆæ€»ç»“")
        print("=" * 60)
        
        if model_path:
            model_size = model_path.stat().st_size / 1024
            print(f"ğŸ“ è®­ç»ƒçš„æ¨¡å‹: {model_path}")
            print(f"ğŸ“ æ¨¡å‹å¤§å°: {model_size:.1f} KB")
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒçš„æ¨¡å‹")
            
        if training_time:
            hours = training_time // 3600
            minutes = (training_time % 3600) // 60
            if hours > 0:
                print(f"â±ï¸  è®­ç»ƒç”¨æ—¶: {hours} å°æ—¶ {minutes} åˆ†é’Ÿ")
            else:
                print(f"â±ï¸  è®­ç»ƒç”¨æ—¶: {minutes} åˆ†é’Ÿ")
                
        print("\nğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œ:")
        print("  1. æµ‹è¯•æ¨¡å‹:")
        print(f"     python nnue_pit.py --model {model_path} --gui")
        print("  2. æŸ¥çœ‹è®­ç»ƒå›¾è¡¨:")
        print("     ls plots/")
        print("  3. ç»§ç»­è®­ç»ƒ:")
        print("     python easy_train.py --high-quality")
        print("  4. éƒ¨ç½²æ¨¡å‹:")
        print("     å°† .bin æ–‡ä»¶å¤åˆ¶åˆ°å¼•æ“ç›®å½•")
        
        print("=" * 60)
        
    def run(self, args):
        """è¿è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹"""
        start_time = time.time()
        
        try:
            # 1. æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
            self.print_banner()
            
            # 2. æ£€æŸ¥ç¯å¢ƒ
            if not self.check_environment():
                return False
                
            # 3. æ£€æŸ¥ç°æœ‰æ¨¡å‹å’Œå¤‡ä»½
            if not self.check_existing_models(force=args.force, auto_backup=args.backup_existing):
                return False  # ç”¨æˆ·é€‰æ‹©å–æ¶ˆè®­ç»ƒ
                
            # 4. æ£€æŸ¥è®­ç»ƒæ¢å¤é€‰é¡¹
            resume_checkpoint = self.check_resume_training()
            
            # 5. å¤„ç†é…ç½®æ–‡ä»¶
            if args.config:
                # ä½¿ç”¨æŒ‡å®šçš„é…ç½®æ–‡ä»¶
                config_path = Path(args.config)
                config = self.load_config_file(args.config)
                if config is None:
                    return False
                    
                # æ£€æŸ¥è®¾å¤‡è®¾ç½®æ˜¯å¦éœ€è¦è­¦å‘Š
                if args.gpu and config.get('device', 'auto') == 'auto':
                    print(f"  âš ï¸  æ³¨æ„: é…ç½®æ–‡ä»¶è®¾å¤‡ä¸º 'auto'ï¼Œä½†æŒ‡å®šäº† --gpu å‚æ•°")
                    print(f"      å»ºè®®åœ¨é…ç½®æ–‡ä»¶ä¸­æ˜ç¡®è®¾ç½® \"device\": \"cuda\"")
                elif config.get('device') == 'auto':
                    print(f"  â„¹ï¸  è®¾å¤‡è®¾ç½®ä¸º 'auto'ï¼Œå°†è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡")
                
                print(f"  âœ… ç›´æ¥ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_path}")
                
            else:
                # ä½¿ç”¨äº¤äº’å¼é¢„è®¾é…ç½®
                preset, device = self.get_user_preferences(args)
                config_path, config = self.create_training_config(preset, device)
            
            # 7. å¦‚æœæœ‰æ¢å¤æ£€æŸ¥ç‚¹ï¼Œæ·»åŠ åˆ°é…ç½®ä¸­
            if resume_checkpoint:
                config["resume_from_checkpoint"] = resume_checkpoint
                # é‡æ–°ä¿å­˜é…ç½®
                with open(config_path, 'w', encoding='utf-8') as f:
                    json.dump(config, f, indent=2, ensure_ascii=False)
                print(f"  âœ… é…ç½®å·²æ›´æ–°ï¼Œå°†ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ")
            
            # 8. ä¼°ç®—æ—¶é—´
            self.estimate_training_time(config)
            
            # 9. ç¡®è®¤å¼€å§‹
            if not args.auto:
                print("\nğŸš€ å‡†å¤‡å¼€å§‹è®­ç»ƒ!")
                choice = input("  ç»§ç»­? (y/n): ").strip().lower()
                if choice not in ['y', 'yes', 'æ˜¯', '']:
                    print("  è®­ç»ƒå·²å–æ¶ˆ")
                    return False
                    
            # 10. è¿è¡Œè®­ç»ƒ
            success = self.run_training(config_path)
            if not success:
                return False
                
            # 11. æŸ¥æ‰¾å’ŒéªŒè¯æ¨¡å‹
            print("ğŸš€ Step 11: Looking for trained model...")
            model_path = self.find_trained_model()
            if model_path:
                print("ğŸš€ Step 11: Model found, starting validation...")
                self.validate_model(model_path)
                print("ğŸš€ Step 11: Model validation completed")
            else:
                print("ğŸš€ Step 11: No model found")
                
            # 12. å¯åŠ¨ GUI æµ‹è¯•
            print("ğŸš€ Step 12: Checking GUI test options...")
            if model_path and not args.no_gui:
                print("ğŸš€ Step 12: Starting GUI test...")
                self.launch_gui_test(model_path)
                print("ğŸš€ Step 12: GUI test completed")
            else:
                print("ğŸš€ Step 12: Skipping GUI test")
                
            # 13. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            print("ğŸš€ Step 13: Cleaning up temporary files...")
            if not args.keep_temp:
                self.cleanup_temp_files()
                print("ğŸš€ Step 13: Cleanup completed")
            else:
                print("ğŸš€ Step 13: Keeping temporary files")
                
            # 14. æ˜¾ç¤ºæ€»ç»“
            training_time = time.time() - start_time
            self.show_summary(model_path, training_time)
            
            return True
            
        except KeyboardInterrupt:
            print("\nâ¹ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
            return False
        except Exception as e:
            print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            return False

def main():
    parser = argparse.ArgumentParser(
        description='NNUE å‚»ç“œåŒ–è®­ç»ƒå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python easy_train.py                    # äº¤äº’å¼è®­ç»ƒ
  python easy_train.py --quick            # å¿«é€Ÿè®­ç»ƒ
  python easy_train.py --high-quality     # é«˜è´¨é‡è®­ç»ƒ
  python easy_train.py --gpu --auto       # è‡ªåŠ¨ GPU è®­ç»ƒ
  python easy_train.py --config config.json  # ä½¿ç”¨é…ç½®æ–‡ä»¶è®­ç»ƒ
  
è®­ç»ƒæ¨¡å¼:
  quick        - 5-10åˆ†é’Ÿï¼Œé€‚åˆæµ‹è¯•å’Œå­¦ä¹ 
  standard     - 30-60åˆ†é’Ÿï¼Œæ—¥å¸¸ä½¿ç”¨æ¨è
  high_quality - 2-4å°æ—¶ï¼Œè¿½æ±‚æœ€ä½³æ•ˆæœ
  config       - ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶

é…ç½®æ–‡ä»¶æ ¼å¼ (JSON):
  {
    "training": {
      "epochs": 100,
      "batch_size": 2048,
      "lr": 0.002,
      "hidden_size": 256,
      "val_split": 0.15
    },
    "device": "auto",
    "plot": true
  }

ä¿æŠ¤åŠŸèƒ½:
  --backup-existing - è‡ªåŠ¨å¤‡ä»½ç°æœ‰æ¨¡å‹
  --force          - å¼ºåˆ¶è®­ç»ƒï¼Œè·³è¿‡ä¿æŠ¤æ£€æŸ¥ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
  
æ–­ç‚¹æ¢å¤:
  ç¨‹åºä¼šè‡ªåŠ¨æ£€æµ‹æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼Œè¯¢é—®æ˜¯å¦æ¢å¤è®­ç»ƒ
        """
    )
    
    parser.add_argument('--quick', action='store_true',
                       help='ä½¿ç”¨å¿«é€Ÿè®­ç»ƒé¢„è®¾ (5-10åˆ†é’Ÿ)')
    parser.add_argument('--high-quality', action='store_true', 
                       help='ä½¿ç”¨é«˜è´¨é‡è®­ç»ƒé¢„è®¾ (2-4å°æ—¶)')
    parser.add_argument('--gpu', action='store_true',
                       help='å¼ºåˆ¶ä½¿ç”¨ GPU (å¦‚æœå¯ç”¨)')
    parser.add_argument('--auto', action='store_true',
                       help='è‡ªåŠ¨æ¨¡å¼ï¼Œä¸è¯¢é—®ç¡®è®¤')
    parser.add_argument('--no-gui', action='store_true',
                       help='è®­ç»ƒå®Œæˆåä¸å¯åŠ¨ GUI')
    parser.add_argument('--keep-temp', action='store_true',
                       help='ä¿ç•™ä¸´æ—¶æ–‡ä»¶')
    parser.add_argument('--force', action='store_true',
                       help='å¼ºåˆ¶è®­ç»ƒï¼Œè·³è¿‡å¤‡ä»½æ£€æŸ¥ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰')
    parser.add_argument('--backup-existing', action='store_true',
                       help='è‡ªåŠ¨å¤‡ä»½ç°æœ‰æ¨¡å‹ï¼Œä¸è¯¢é—®')
    parser.add_argument('--config', type=str, metavar='FILE',
                       help='ä½¿ç”¨æŒ‡å®šçš„é…ç½®æ–‡ä»¶ (JSONæ ¼å¼)')
    
    args = parser.parse_args()
    
    # éªŒè¯å‚æ•°
    if args.quick and args.high_quality:
        print("âŒ ä¸èƒ½åŒæ—¶æŒ‡å®š --quick å’Œ --high-quality")
        return 1
        
    # éªŒè¯é…ç½®æ–‡ä»¶å‚æ•°
    if args.config and (args.quick or args.high_quality):
        print("âŒ ä½¿ç”¨é…ç½®æ–‡ä»¶æ—¶ä¸èƒ½åŒæ—¶æŒ‡å®šé¢„è®¾é€‰é¡¹ (--quick/--high-quality)")
        return 1
        
    # è¿è¡Œè®­ç»ƒå™¨
    trainer = EasyNNUETrainer()
    success = trainer.run(args)
    
    return 0 if success else 1

if __name__ == '__main__':
    sys.exit(main())

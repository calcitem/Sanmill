#!/usr/bin/env python3
"""
NNUE Model Cleanup Tool - NNUE æ¨¡å‹æ¸…ç†å·¥å…·
===========================================

è¿™ä¸ªå·¥å…·å¸®åŠ©æ¸…ç†é‡å¤å’Œè¿‡æœŸçš„ NNUE æ¨¡å‹æ–‡ä»¶ï¼Œç»´æŠ¤æ¸…æ´çš„æ¨¡å‹ç›®å½•ç»“æ„ã€‚

ä½¿ç”¨æ–¹æ³•:
  python model_cleanup.py --list            # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹æ–‡ä»¶
  python model_cleanup.py --dry-run         # æ¨¡æ‹Ÿæ¸…ç†ï¼ˆä¸å®é™…åˆ é™¤ï¼‰
  python model_cleanup.py --backup-only     # ä»…æ¸…ç†å¤‡ä»½æ–‡ä»¶
  python model_cleanup.py --interactive     # äº¤äº’å¼æ¸…ç†
  python model_cleanup.py --auto            # è‡ªåŠ¨æ¸…ç†ï¼ˆä¿ç•™æœ€æ–°çš„3ä¸ªæ¨¡å‹ï¼‰
"""

import os
import sys
import time
import argparse
import shutil
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Tuple

class ModelCleanupTool:
    """NNUE æ¨¡å‹æ¸…ç†å·¥å…·"""
    
    def __init__(self, project_root=None):
        if project_root is None:
            project_root = Path(__file__).parent
        self.project_root = Path(project_root)
        self.models_dir = self.project_root / "models"
        self.nnue_output_dir = self.project_root / "nnue_output"
        
    def scan_model_files(self) -> Dict[str, List[Path]]:
        """æ‰«ææ‰€æœ‰æ¨¡å‹æ–‡ä»¶"""
        model_files = {
            'models': [],
            'nnue_output': [],
            'root': [],
            'backups': []
        }
        
        # æ‰«æ models ç›®å½•
        if self.models_dir.exists():
            for pattern in ['*.bin', '*.pth', '*.pytorch', '*.tar']:
                model_files['models'].extend(self.models_dir.glob(pattern))
            
            # æ‰«æå¤‡ä»½æ–‡ä»¶
            for pattern in ['*.backup_*', '*.bak']:
                model_files['backups'].extend(self.models_dir.glob(pattern))
        
        # æ‰«æ nnue_output ç›®å½•
        if self.nnue_output_dir.exists():
            for pattern in ['*.bin', '*.pth', '*.pytorch', '*.tar']:
                model_files['nnue_output'].extend(self.nnue_output_dir.glob(pattern))
        
        # æ‰«æé¡¹ç›®æ ¹ç›®å½•
        for pattern in ['nnue_model*.bin', 'nnue_model*.pth', 'model*.bin', 'model*.pth']:
            model_files['root'].extend(self.project_root.glob(pattern))
            
        return model_files
    
    def analyze_files(self, model_files: Dict[str, List[Path]]) -> Dict:
        """åˆ†ææ¨¡å‹æ–‡ä»¶"""
        analysis = {
            'total_files': 0,
            'total_size_mb': 0,
            'by_category': {},
            'duplicates': [],
            'old_backups': [],
            'large_files': []
        }
        
        all_files = []
        for category, files in model_files.items():
            analysis['by_category'][category] = {
                'count': len(files),
                'size_mb': 0,
                'files': []
            }
            
            for file_path in files:
                if file_path.exists():
                    stat = file_path.stat()
                    size_mb = stat.st_size / (1024 * 1024)
                    mtime = datetime.fromtimestamp(stat.st_mtime)
                    
                    file_info = {
                        'path': file_path,
                        'category': category,
                        'size_mb': size_mb,
                        'mtime': mtime,
                        'age_days': (datetime.now() - mtime).days
                    }
                    
                    analysis['by_category'][category]['files'].append(file_info)
                    analysis['by_category'][category]['size_mb'] += size_mb
                    analysis['total_size_mb'] += size_mb
                    all_files.append(file_info)
        
        analysis['total_files'] = len(all_files)
        
        # æŸ¥æ‰¾å¯èƒ½çš„é‡å¤æ–‡ä»¶ï¼ˆåŸºäºåç§°å’Œå¤§å°ï¼‰
        self._find_duplicates(all_files, analysis)
        
        # æŸ¥æ‰¾æ—§å¤‡ä»½æ–‡ä»¶ï¼ˆè¶…è¿‡30å¤©ï¼‰
        analysis['old_backups'] = [
            f for f in all_files 
            if f['category'] == 'backups' and f['age_days'] > 30
        ]
        
        # æŸ¥æ‰¾å¤§æ–‡ä»¶ï¼ˆè¶…è¿‡50MBï¼‰
        analysis['large_files'] = [
            f for f in all_files 
            if f['size_mb'] > 50
        ]
        
        return analysis
    
    def _find_duplicates(self, all_files: List[Dict], analysis: Dict):
        """æŸ¥æ‰¾é‡å¤æ–‡ä»¶"""
        # æŒ‰æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰åˆ†ç»„
        by_name = {}
        for file_info in all_files:
            name = file_info['path'].name
            # å¿½ç•¥å¤‡ä»½æ–‡ä»¶çš„æ—¶é—´æˆ³
            if '.backup_' in name:
                base_name = name.split('.backup_')[0]
            else:
                base_name = name
                
            if base_name not in by_name:
                by_name[base_name] = []
            by_name[base_name].append(file_info)
        
        # æ‰¾åˆ°æœ‰å¤šä¸ªæ–‡ä»¶çš„åç§°ç»„
        for name, files in by_name.items():
            if len(files) > 1:
                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
                files.sort(key=lambda f: f['mtime'], reverse=True)
                analysis['duplicates'].append({
                    'name': name,
                    'files': files,
                    'latest': files[0],
                    'duplicates': files[1:]
                })
    
    def print_analysis(self, analysis: Dict):
        """æ‰“å°åˆ†æç»“æœ"""
        print("\nğŸ“Š NNUE æ¨¡å‹æ–‡ä»¶åˆ†ææŠ¥å‘Š")
        print("=" * 50)
        
        print(f"\nğŸ“ˆ æ€»è§ˆ:")
        print(f"  æ–‡ä»¶æ€»æ•°: {analysis['total_files']}")
        print(f"  æ€»å¤§å°: {analysis['total_size_mb']:.1f} MB")
        
        print(f"\nğŸ“ æŒ‰ç›®å½•åˆ†å¸ƒ:")
        for category, info in analysis['by_category'].items():
            if info['count'] > 0:
                category_name = {
                    'models': 'models/ (æ¨èä½ç½®)',
                    'nnue_output': 'nnue_output/ (æ—§è¾“å‡º)',
                    'root': 'é¡¹ç›®æ ¹ç›®å½•',
                    'backups': 'å¤‡ä»½æ–‡ä»¶'
                }[category]
                
                print(f"  {category_name}: {info['count']} ä¸ªæ–‡ä»¶, {info['size_mb']:.1f} MB")
                
                # æ˜¾ç¤ºæœ€æ–°çš„å‡ ä¸ªæ–‡ä»¶
                if info['files']:
                    sorted_files = sorted(info['files'], key=lambda f: f['mtime'], reverse=True)
                    for file_info in sorted_files[:3]:  # åªæ˜¾ç¤ºæœ€æ–°çš„3ä¸ª
                        age_str = f"{file_info['age_days']}å¤©å‰" if file_info['age_days'] > 0 else "ä»Šå¤©"
                        print(f"    â€¢ {file_info['path'].name} ({file_info['size_mb']:.1f}MB, {age_str})")
                    
                    if len(sorted_files) > 3:
                        print(f"    ... è¿˜æœ‰ {len(sorted_files) - 3} ä¸ªæ–‡ä»¶")
        
        if analysis['duplicates']:
            print(f"\nğŸ”„ å¯èƒ½çš„é‡å¤æ–‡ä»¶ ({len(analysis['duplicates'])} ç»„):")
            for dup in analysis['duplicates'][:5]:  # åªæ˜¾ç¤ºå‰5ç»„
                print(f"  ğŸ“„ {dup['name']}:")
                print(f"    âœ… æœ€æ–°: {dup['latest']['path']} ({dup['latest']['age_days']}å¤©å‰)")
                for old in dup['duplicates']:
                    print(f"    ğŸ—‘ï¸  æ—§ç‰ˆ: {old['path']} ({old['age_days']}å¤©å‰)")
        
        if analysis['old_backups']:
            print(f"\nğŸ—‚ï¸ æ—§å¤‡ä»½æ–‡ä»¶ ({len(analysis['old_backups'])} ä¸ª, è¶…è¿‡30å¤©):")
            for backup in analysis['old_backups'][:5]:
                print(f"  ğŸ—‘ï¸  {backup['path'].name} ({backup['age_days']}å¤©å‰, {backup['size_mb']:.1f}MB)")
            if len(analysis['old_backups']) > 5:
                print(f"  ... è¿˜æœ‰ {len(analysis['old_backups']) - 5} ä¸ªæ—§å¤‡ä»½æ–‡ä»¶")
        
        if analysis['large_files']:
            print(f"\nğŸ“¦ å¤§æ–‡ä»¶ ({len(analysis['large_files'])} ä¸ª, è¶…è¿‡50MB):")
            for large in sorted(analysis['large_files'], key=lambda f: f['size_mb'], reverse=True):
                print(f"  ğŸ“¦ {large['path'].name} ({large['size_mb']:.1f}MB)")
    
    def interactive_cleanup(self, analysis: Dict):
        """äº¤äº’å¼æ¸…ç†"""
        print("\nğŸ§¹ äº¤äº’å¼æ¸…ç†æ¨¡å¼")
        print("=" * 30)
        
        total_saved = 0
        
        # å¤„ç†é‡å¤æ–‡ä»¶
        if analysis['duplicates']:
            print("\nğŸ”„ å¤„ç†é‡å¤æ–‡ä»¶:")
            for dup in analysis['duplicates']:
                print(f"\nğŸ“„ å‘ç°é‡å¤æ–‡ä»¶ç»„: {dup['name']}")
                print(f"  âœ… æœ€æ–°: {dup['latest']['path']} ({dup['latest']['age_days']}å¤©å‰)")
                
                for i, old in enumerate(dup['duplicates']):
                    print(f"  {i+1}. ğŸ—‘ï¸  {old['path']} ({old['age_days']}å¤©å‰, {old['size_mb']:.1f}MB)")
                
                choice = input("åˆ é™¤æ—§ç‰ˆæœ¬? (y/n/s=è·³è¿‡): ").lower()
                if choice == 'y':
                    for old in dup['duplicates']:
                        try:
                            os.remove(old['path'])
                            print(f"    âœ… å·²åˆ é™¤: {old['path'].name}")
                            total_saved += old['size_mb']
                        except Exception as e:
                            print(f"    âŒ åˆ é™¤å¤±è´¥: {e}")
                elif choice == 's':
                    continue
        
        # å¤„ç†æ—§å¤‡ä»½æ–‡ä»¶
        if analysis['old_backups']:
            print(f"\nğŸ—‚ï¸ å‘ç° {len(analysis['old_backups'])} ä¸ªæ—§å¤‡ä»½æ–‡ä»¶ (è¶…è¿‡30å¤©)")
            choice = input("åˆ é™¤æ‰€æœ‰æ—§å¤‡ä»½æ–‡ä»¶? (y/n): ").lower()
            if choice == 'y':
                for backup in analysis['old_backups']:
                    try:
                        os.remove(backup['path'])
                        print(f"  âœ… å·²åˆ é™¤å¤‡ä»½: {backup['path'].name}")
                        total_saved += backup['size_mb']
                    except Exception as e:
                        print(f"  âŒ åˆ é™¤å¤±è´¥: {e}")
        
        print(f"\nâœ… æ¸…ç†å®Œæˆ! é‡Šæ”¾äº† {total_saved:.1f} MB ç©ºé—´")
    
    def auto_cleanup(self, keep_latest=3, keep_backups_days=7, dry_run=False):
        """è‡ªåŠ¨æ¸…ç†"""
        print(f"\nğŸ¤– è‡ªåŠ¨æ¸…ç†æ¨¡å¼ (ä¿ç•™æœ€æ–° {keep_latest} ä¸ªæ¨¡å‹, {keep_backups_days} å¤©å†…çš„å¤‡ä»½)")
        print("=" * 60)
        
        total_saved = 0
        actions = []
        
        model_files = self.scan_model_files()
        
        # æ¸…ç†æ¯ä¸ªç›®å½•ä¸­çš„æ—§æ¨¡å‹æ–‡ä»¶
        for category in ['models', 'nnue_output', 'root']:
            files = model_files[category]
            if not files:
                continue
                
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
            files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
            
            if len(files) > keep_latest:
                old_files = files[keep_latest:]
                print(f"\nğŸ“ {category} ç›®å½•:")
                print(f"  ä¿ç•™æœ€æ–°çš„ {keep_latest} ä¸ªæ–‡ä»¶")
                print(f"  åˆ é™¤ {len(old_files)} ä¸ªæ—§æ–‡ä»¶:")
                
                for old_file in old_files:
                    size_mb = old_file.stat().st_size / (1024 * 1024)
                    age = (datetime.now() - datetime.fromtimestamp(old_file.stat().st_mtime)).days
                    print(f"    ğŸ—‘ï¸  {old_file.name} ({size_mb:.1f}MB, {age}å¤©å‰)")
                    
                    if not dry_run:
                        try:
                            os.remove(old_file)
                            total_saved += size_mb
                            actions.append(f"åˆ é™¤æ—§æ¨¡å‹: {old_file.name}")
                        except Exception as e:
                            print(f"    âŒ åˆ é™¤å¤±è´¥: {e}")
                    else:
                        total_saved += size_mb
        
        # æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶
        backup_files = model_files['backups']
        if backup_files:
            cutoff_date = datetime.now() - timedelta(days=keep_backups_days)
            old_backups = [
                f for f in backup_files 
                if datetime.fromtimestamp(f.stat().st_mtime) < cutoff_date
            ]
            
            if old_backups:
                print(f"\nğŸ—‚ï¸ æ¸…ç†è¶…è¿‡ {keep_backups_days} å¤©çš„å¤‡ä»½æ–‡ä»¶:")
                for backup in old_backups:
                    size_mb = backup.stat().st_size / (1024 * 1024)
                    age = (datetime.now() - datetime.fromtimestamp(backup.stat().st_mtime)).days
                    print(f"  ğŸ—‘ï¸  {backup.name} ({size_mb:.1f}MB, {age}å¤©å‰)")
                    
                    if not dry_run:
                        try:
                            os.remove(backup)
                            total_saved += size_mb
                            actions.append(f"åˆ é™¤æ—§å¤‡ä»½: {backup.name}")
                        except Exception as e:
                            print(f"    âŒ åˆ é™¤å¤±è´¥: {e}")
                    else:
                        total_saved += size_mb
        
        mode_str = "é¢„è®¡é‡Šæ”¾" if dry_run else "å®é™…é‡Šæ”¾"
        print(f"\nâœ… è‡ªåŠ¨æ¸…ç†å®Œæˆ! {mode_str} {total_saved:.1f} MB ç©ºé—´")
        
        if actions and not dry_run:
            print(f"\nğŸ“ æ‰§è¡Œçš„æ“ä½œ:")
            for action in actions:
                print(f"  â€¢ {action}")

def main():
    parser = argparse.ArgumentParser(description='NNUE Model Cleanup Tool')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºæ‰€æœ‰æ¨¡å‹æ–‡ä»¶')
    parser.add_argument('--dry-run', action='store_true', help='æ¨¡æ‹Ÿæ¸…ç†ï¼ˆä¸å®é™…åˆ é™¤ï¼‰')
    parser.add_argument('--backup-only', action='store_true', help='ä»…æ¸…ç†å¤‡ä»½æ–‡ä»¶')
    parser.add_argument('--interactive', action='store_true', help='äº¤äº’å¼æ¸…ç†')
    parser.add_argument('--auto', action='store_true', help='è‡ªåŠ¨æ¸…ç†')
    parser.add_argument('--keep-latest', type=int, default=3, help='ä¿ç•™æœ€æ–°çš„å‡ ä¸ªæ¨¡å‹æ–‡ä»¶ (é»˜è®¤: 3)')
    parser.add_argument('--keep-backups-days', type=int, default=7, help='ä¿ç•™å‡ å¤©å†…çš„å¤‡ä»½æ–‡ä»¶ (é»˜è®¤: 7)')
    
    args = parser.parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ“ä½œï¼Œé»˜è®¤ä¸ºåˆ—å‡ºæ–‡ä»¶
    if not any([args.list, args.dry_run, args.backup_only, args.interactive, args.auto]):
        args.list = True
    
    tool = ModelCleanupTool()
    model_files = tool.scan_model_files()
    analysis = tool.analyze_files(model_files)
    
    if args.list or args.dry_run or args.interactive or args.auto:
        tool.print_analysis(analysis)
    
    if args.interactive:
        tool.interactive_cleanup(analysis)
    elif args.auto:
        tool.auto_cleanup(
            keep_latest=args.keep_latest,
            keep_backups_days=args.keep_backups_days,
            dry_run=args.dry_run
        )
    elif args.backup_only:
        print("\nğŸ—‚ï¸ ä»…æ¸…ç†å¤‡ä»½æ–‡ä»¶æ¨¡å¼")
        if analysis['old_backups']:
            choice = input(f"å‘ç° {len(analysis['old_backups'])} ä¸ªæ—§å¤‡ä»½æ–‡ä»¶ï¼Œæ˜¯å¦åˆ é™¤? (y/n): ")
            if choice.lower() == 'y':
                for backup in analysis['old_backups']:
                    try:
                        if not args.dry_run:
                            os.remove(backup['path'])
                        print(f"  {'âœ… å·²åˆ é™¤' if not args.dry_run else 'ğŸ” å°†åˆ é™¤'}: {backup['path'].name}")
                    except Exception as e:
                        print(f"  âŒ åˆ é™¤å¤±è´¥: {e}")
        else:
            print("  ğŸ“­ æ²¡æœ‰å‘ç°æ—§å¤‡ä»½æ–‡ä»¶")

if __name__ == '__main__':
    main()
